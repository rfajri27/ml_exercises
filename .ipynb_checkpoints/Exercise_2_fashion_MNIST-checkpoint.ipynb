{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-forth",
   "metadata": {},
   "source": [
    "# Fashion Clasifications\n",
    "\n",
    "In this exercise, we are using **Fashion MNIST Data Set**. This data set contain:\n",
    "* 70K image of clothing\n",
    "* 10 Categories\n",
    "* Each image are 28x28\n",
    "* Each pixel-value is an integer between 0 and 255\n",
    "* Using numbers for labeling each image\n",
    "* Can train a neural net!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-blood",
   "metadata": {},
   "source": [
    "## Load training and testing data\n",
    "\n",
    "In this model, we will use 60K image data to train the network and 10K image data to test our model.\n",
    "\n",
    "* train_images/test_images : data image\n",
    "* train_labels/test_labels : label of each image\n",
    "\n",
    "Label | Description\n",
    "--- | ---\n",
    "0 | T-shirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Sirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-stand",
   "metadata": {},
   "source": [
    "## Plot data images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incoming-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  48  88  54  25  19   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  4   1   1   1   0   0 206 204 106 163 178 157 163 171 119  39   0   0\n",
      "    2   1   1   1   1   1   1   1   0   0]\n",
      " [  0   0   0   0   0  84 204   0   0   0   1  57  91  77  99 138  94   7\n",
      "    0   0   0   0   0   0   0   0   1   3]\n",
      " [ 51  43  27  27  28 254  31   0   4   0   0   0  16 121  84  19  63 110\n",
      "   31   0   0   0   0   0   0   0   0   0]\n",
      " [137 202 133 108  97 146  71  78  82  86  85 105 118 139 143 126 162 176\n",
      "  135  69  76  71  91  99 103  94  99  54]\n",
      " [  0 110 186 205 203 193 191 178 204 172 175 175 177 183 189 190 197 196\n",
      "  192 182 186 185 184 182 178 168 159  77]\n",
      " [  0   0   0   4  51  69  92 108 112 115 112 111 112  90  77  62  44  36\n",
      "   32  35  27  25  19  14   5   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANh0lEQVR4nO3dX4xc9XnG8edhvbZT2yQ4xsbBKCEWqkqbYqqtSUvTpqJFjm9MLhLFF5EroTgXQSJVLooSqeESVU1QVVWRTLHiVik0CkFYldvGcqlQlASxJq4xuMRAHTBe+U+MwDZ4vet9e7GHaGP2/M4yc+YPeb8faTUz550z5/XsPp4/v3POzxEhAL/+rhh0AwD6g7ADSRB2IAnCDiRB2IEkFvVzY4u9JJZqWT83CaRyQed1MSY9X62rsNveJOnvJI1I+seIuK90/6Vaplt8WzebBFDwZOyrrXX8Nt72iKR/kPQpSTdK2mr7xk4fD0BvdfOZfaOkFyLipYi4KOlhSVvaaQtA27oJ+7WSXplz+1i17FfY3m573Pb4lCa72ByAbnQT9vm+BHjHvrcRsSMixiJibFRLutgcgG50E/Zjkq6bc3udpOPdtQOgV7oJ+1OSbrB9ve3Fkj4naXc7bQFoW8dDbxExbfsuSf+p2aG3nRHxbGudAWhVV+PsEbFH0p6WegHQQ+wuCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiiqymbbR+VdFbSJUnTETHWRlMA2tdV2Ct/GhGnW3gcAD3E23ggiW7DHpJ+YHu/7e3z3cH2dtvjtsenNNnl5gB0qtu38bdGxHHbqyXttf2/EfHE3DtExA5JOyTpSq+MLrcHoENdvbJHxPHq8qSkRyVtbKMpAO3rOOy2l9le8fZ1SbdLOtRWYwDa1c3b+DWSHrX99uP8S0T8RytdAWhdx2GPiJck3dRiLwB6iKE3IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKNYbe90/ZJ24fmLFtpe6/tI9XlVb1tE0C3FvLK/m1Jmy5bdo+kfRFxg6R91W0AQ6wx7BHxhKQzly3eImlXdX2XpDvabQtA2zr9zL4mIiYkqbpcXXdH29ttj9sen9Jkh5sD0K2ef0EXETsiYiwixka1pNebA1Cj07CfsL1WkqrLk+21BKAXOg37bknbquvbJD3WTjsAemVR0x1sPyTpk5JW2T4m6euS7pP0Xdt3SnpZ0md62eR73cyf3Fys/+LGpcX6B16cKtbf98Lp+uLkxeK6068eL9Z7yi7XI/rTRxKNYY+IrTWl21ruBUAPsQcdkARhB5Ig7EAShB1IgrADSTR+G98qWx5dXFuO6fIQU1e6HMb5xMELtbWpGCmu+71/fV+xvmjja8X66IqzxfpLZ+oPOlw8Ol1cd/nS8rDfqZ+uKdY/+ki5txg/VCg2/E6uKD+viply/b2qR0OOvLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL9HWePUEyVD7kclF984Q+K9al4orb2k5tGi+uu04866umXGg4FXbNpbW3t9fXl3qbfKI/pLlld3vbzXyjvQ3DlrX9YW/vQAweK6868+Wax/mur4fftkcL+B4XdKnhlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHH08Xe+KK9fF2Ma7ausjb5WPvV50unzsdFHD2OWe/36kWN/8Z5+trV167mflTReO4ZfU030PRtbUzswlSTryl+uL9fe/WH78NXt+Xqyf/f11tbVTv1vezeP67xVOka3m5z2jJ2Of3ogz8/6x88oOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dZx9yYfXxTVfu7u2vvWWnxTXf/hH9cecL50on2N8UcOh0eduqj8vvCRd8+/1Y+XTS8pj+DMNZw2IprMKNPyKLnywfvtTK8orT60q79ugReX1R14rN/8b61+vrV29/Hxx3ZeOXFOsf+jx8mtV6fcyMlX+d721quGxy6fbb/ydjrxVX5spn4JAVx+s3y9j/4//XmdfP9bZOLvtnbZP2j40Z9m9tl+1faD62dz0OAAGayFv478tadM8y++PiA3Vz5522wLQtsawR8QTks70oRcAPdTNF3R32T5Yvc2vnWzM9nbb47bHL50rf0YD0Dudhv1bktZL2iBpQtI36u4YETsiYiwixkaWL+twcwC61VHYI+JERFyKiBlJD0ja2G5bANrWUdhtzz138aclFeblBTAMGsfZbT8k6ZOSVkk6Ienr1e0Nmh0BPirpixEx0bSxK70ybvFttfWX/7r+HOOS9LHbn6+t/faK8uab5lA/MXllsT4d9f8vHj///uK6H1/1f8X6vonfLNZHRy4V6yWLrijPYb5sUflY+uWjk8X6FS4//gdG6weUZwrPqSS9dak84HxqcnmxvnRkqrDthn0jGurTDX9Pk9PlgfbXLtSfb//8hfL5D5Y/Vv+3+ty/3a/zp1+Zt/nGSSIiYus8ix9sWg/AcGF3WSAJwg4kQdiBJAg7kARhB5Lo6yGuTUNv3Wg6XfPUJz5WrF9YVR7mOb+m/v/Fi+WRt8bDHWdGyr+DKy6Vh4GKh8A2rLr0VLm++GzDlM6vl4cFl56qH7obebN+aEySPFV+7FhUfq3ym/Xb9qXykKEmy0OSMVkekpw5e66r9TvFqaQBEHYgC8IOJEHYgSQIO5AEYQeSIOxAEo1Hvb1XNE17vOi/9hfr5YMlm+t49xpGutEyXtmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNEYdtvX2X7c9mHbz9q+u1q+0vZe20eqy6t63y6ATi3klX1a0lci4rckfVzSl2zfKOkeSfsi4gZJ+6rbAIZUY9gjYiIinq6un5V0WNK1krZI2lXdbZekO3rUI4AWvKvP7LY/IulmSU9KWhMRE9LsfwiSVtess932uO3xKfVmfisAzRYcdtvLJT0i6csR8cZC14uIHRExFhFjo1rSSY8AWrCgsNse1WzQvxMR368Wn7C9tqqvlXSyNy0CaMNCvo23pAclHY6Ib84p7Za0rbq+TdJj7bcHoC0LOW/8rZI+L+kZ2weqZV+VdJ+k79q+U9LLkj7Tkw4BtKIx7BHxQ0nzTu4u6bZ22wHQK+xBByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBILmZ/9OtuP2z5s+1nbd1fL77X9qu0D1c/m3rcLoFMLmZ99WtJXIuJp2ysk7be9t6rdHxF/27v2ALRlIfOzT0iaqK6ftX1Y0rW9bgxAu97VZ3bbH5F0s6Qnq0V32T5oe6ftq2rW2W573Pb4lCa76xZAxxYcdtvLJT0i6csR8Yakb0laL2mDZl/5vzHfehGxIyLGImJsVEu67xhARxYUdtujmg36dyLi+5IUESci4lJEzEh6QNLG3rUJoFsL+Tbekh6UdDgivjln+do5d/u0pEPttwegLQv5Nv5WSZ+X9IztA9Wyr0raanuDpJB0VNIXe9AfgJYs5Nv4H0ryPKU97bcDoFfYgw5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5CEI6J/G7NPSfr5nEWrJJ3uWwPvzrD2Nqx9SfTWqTZ7+3BEXD1foa9hf8fG7fGIGBtYAwXD2tuw9iXRW6f61Rtv44EkCDuQxKDDvmPA2y8Z1t6GtS+J3jrVl94G+pkdQP8M+pUdQJ8QdiCJgYTd9ibbz9t+wfY9g+ihju2jtp+ppqEeH3AvO22ftH1ozrKVtvfaPlJdzjvH3oB6G4ppvAvTjA/0uRv09Od9/8xue0TSzyT9uaRjkp6StDUinutrIzVsH5U0FhED3wHD9h9LOifpnyLid6plfyPpTETcV/1HeVVE/NWQ9HavpHODnsa7mq1o7dxpxiXdIekvNMDnrtDXZ9WH520Qr+wbJb0QES9FxEVJD0vaMoA+hl5EPCHpzGWLt0jaVV3fpdk/lr6r6W0oRMRERDxdXT8r6e1pxgf63BX66otBhP1aSa/MuX1MwzXfe0j6ge39trcPupl5rImICWn2j0fS6gH3c7nGabz76bJpxofmuetk+vNuDSLs800lNUzjf7dGxO9J+pSkL1VvV7EwC5rGu1/mmWZ8KHQ6/Xm3BhH2Y5Kum3N7naTjA+hjXhFxvLo8KelRDd9U1CfenkG3ujw54H5+aZim8Z5vmnENwXM3yOnPBxH2pyTdYPt624slfU7S7gH08Q62l1VfnMj2Mkm3a/imot4taVt1fZukxwbYy68Ylmm866YZ14Cfu4FPfx4Rff+RtFmz38i/KOlrg+ihpq+PSvqf6ufZQfcm6SHNvq2b0uw7ojslfVDSPklHqsuVQ9TbP0t6RtJBzQZr7YB6+yPNfjQ8KOlA9bN50M9doa++PG/sLgskwR50QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wNcjTRwf6FB3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_images[30])\n",
    "print(training_labels[30])\n",
    "print(training_images[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-retro",
   "metadata": {},
   "source": [
    "## Normalazing\n",
    "\n",
    "The values in the number are between 0 and 255. The training process will easier if we treat all values as between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuck-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accompanied-studio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18823529 0.34509804 0.21176471 0.09803922\n",
      "  0.0745098  0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.01568627 0.00392157 0.00392157 0.00392157 0.         0.\n",
      "  0.80784314 0.8        0.41568627 0.63921569 0.69803922 0.61568627\n",
      "  0.63921569 0.67058824 0.46666667 0.15294118 0.         0.\n",
      "  0.00784314 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.32941176\n",
      "  0.8        0.         0.         0.         0.00392157 0.22352941\n",
      "  0.35686275 0.30196078 0.38823529 0.54117647 0.36862745 0.02745098\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.01176471]\n",
      " [0.2        0.16862745 0.10588235 0.10588235 0.10980392 0.99607843\n",
      "  0.12156863 0.         0.01568627 0.         0.         0.\n",
      "  0.0627451  0.4745098  0.32941176 0.0745098  0.24705882 0.43137255\n",
      "  0.12156863 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.5372549  0.79215686 0.52156863 0.42352941 0.38039216 0.57254902\n",
      "  0.27843137 0.30588235 0.32156863 0.3372549  0.33333333 0.41176471\n",
      "  0.4627451  0.54509804 0.56078431 0.49411765 0.63529412 0.69019608\n",
      "  0.52941176 0.27058824 0.29803922 0.27843137 0.35686275 0.38823529\n",
      "  0.40392157 0.36862745 0.38823529 0.21176471]\n",
      " [0.         0.43137255 0.72941176 0.80392157 0.79607843 0.75686275\n",
      "  0.74901961 0.69803922 0.8        0.6745098  0.68627451 0.68627451\n",
      "  0.69411765 0.71764706 0.74117647 0.74509804 0.77254902 0.76862745\n",
      "  0.75294118 0.71372549 0.72941176 0.7254902  0.72156863 0.71372549\n",
      "  0.69803922 0.65882353 0.62352941 0.30196078]\n",
      " [0.         0.         0.         0.01568627 0.2        0.27058824\n",
      "  0.36078431 0.42352941 0.43921569 0.45098039 0.43921569 0.43529412\n",
      "  0.43921569 0.35294118 0.30196078 0.24313725 0.17254902 0.14117647\n",
      "  0.1254902  0.1372549  0.10588235 0.09803922 0.0745098  0.05490196\n",
      "  0.01960784 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[30])\n",
    "print(training_images[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-romantic",
   "metadata": {},
   "source": [
    "## Making model\n",
    "\n",
    "we will make 3 layers of NN. The first layer is the input layer in the shape of the data. The second layer is the hidden layer, this layer will try to figure out the role between the input layer & output layer. The last is the output layer in the shape of the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recorded-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-command",
   "metadata": {},
   "source": [
    "* `Sequential`: That defines a sequence of layers in the neural network\n",
    "* `Flatten`: That turns the data set into a 1-dimensional set\n",
    "* `Dense`: Adds a layer of neurons, each layer needs an **activation function** to tell the neurons what to do\n",
    "* `Relu`: \"if x>0 retuurn x, else return 0\"\n",
    "* `softmax`: Takes a set of values, and picks the biggest one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-moscow",
   "metadata": {},
   "source": [
    "## Compiling & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "satisfactory-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5944 - accuracy: 0.7885\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3640 - accuracy: 0.8672\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3250 - accuracy: 0.8824\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3012 - accuracy: 0.8872\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2796 - accuracy: 0.8974\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2682 - accuracy: 0.8999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3c9d61e20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-doctor",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spare-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3450760841369629, 0.8763999938964844]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-queens",
   "metadata": {},
   "source": [
    "## Clasifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "banner-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2012293e-06 2.4755172e-08 8.0213143e-09 1.3252681e-09 1.2631924e-07\n",
      " 1.6982274e-04 5.6952155e-07 1.7329976e-02 2.9746975e-06 9.8249233e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-links",
   "metadata": {},
   "source": [
    "The output of this model is a list of 10 numbers. The numbers are a probability that this item is each of 10 classes. \n",
    "\n",
    "The list having the 10th element being the highest value means that the Neural Network has predicted that the item it is classifying is most likely an ankle boot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "federal-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3ac096790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_labels[0])\n",
    "plt.imshow(test_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-laugh",
   "metadata": {},
   "source": [
    "## Using callbacks to control training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lovely-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5864 - accuracy: 0.7926\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c3a8dcbbd6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m              metrics=['accuracy'])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ML-env/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c3a8dcbbd6b6>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mmyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nReached 90% accuracy so cancelling training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.99):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model  = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranking-turkey",
   "metadata": {},
   "source": [
    "# Improving Fashion Clasifications Accuracy using Convolutions\n",
    "\n",
    "In this exercise, we are using **Fashion MNIST Data Set** and **Convolutions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-genre",
   "metadata": {},
   "source": [
    "## Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fuzzy-version",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ddf99245cfea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-pierre",
   "metadata": {},
   "source": [
    "## Normalazing & Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surface-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images = training_images / 255.0\n",
    "\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-bouquet",
   "metadata": {},
   "source": [
    "The training data and testing data needed to reshaped because the first convolution expects a single tensor containing everything, so instead of 60000 28x28x1 item in a list, we have a single 4D list that is 60000x28x28x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "average-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_images[20])\n",
    "print(training_labels[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-disclosure",
   "metadata": {},
   "source": [
    "## Making model\n",
    "\n",
    "The first layer is the convolutions layer with 64 filters and (3,3) filter shape. The second layer is the pooling layer with (2,2) shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extraordinary-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-crawford",
   "metadata": {},
   "source": [
    "## Compiling & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "synthetic-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.6024 - accuracy: 0.7767\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.3024 - accuracy: 0.8904\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.2517 - accuracy: 0.9082\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.2160 - accuracy: 0.9195\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 117s 62ms/step - loss: 0.1856 - accuracy: 0.9313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f417da43190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-statistics",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-supply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2634 - accuracy: 0.9014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2633627653121948, 0.9014000296592712]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
